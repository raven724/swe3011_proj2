Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 32, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 64)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 64)        256       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
dropout_2 (Dropout)          (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 128)       0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    
_________________________________________________________________
activation_5 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
dropout_3 (Dropout)          (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    
_________________________________________________________________
activation_6 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
dropout_4 (Dropout)          (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    
_________________________________________________________________
activation_7 (Activation)    (None, 8, 8, 256)         0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   
_________________________________________________________________
activation_8 (Activation)    (None, 4, 4, 512)         0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
dropout_5 (Dropout)          (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   
_________________________________________________________________
activation_9 (Activation)    (None, 4, 4, 512)         0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
dropout_6 (Dropout)          (None, 4, 4, 512)         0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   
_________________________________________________________________
activation_10 (Activation)   (None, 4, 4, 512)         0         
_________________________________________________________________
batch_normalization_10 (Batc (None, 4, 4, 512)         2048      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_11 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
batch_normalization_11 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 512)         0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_12 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
batch_normalization_12 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
dropout_8 (Dropout)          (None, 2, 2, 512)         0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   
_________________________________________________________________
activation_13 (Activation)   (None, 2, 2, 512)         0         
_________________________________________________________________
batch_normalization_13 (Batc (None, 2, 2, 512)         2048      
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               262656    
_________________________________________________________________
activation_14 (Activation)   (None, 512)               0         
_________________________________________________________________
batch_normalization_14 (Batc (None, 512)               2048      
_________________________________________________________________
dropout_9 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5130      
_________________________________________________________________
activation_15 (Activation)   (None, 10)                0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 10)                0         
=================================================================
Total params: 15,001,418
Trainable params: 14,991,946
Non-trainable params: 9,472
_________________________________________________________________
Epoch 1/100
2019-11-30 13:58:14.043336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-11-30 13:58:14.291891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
390/390 [==============================] - 52s 133ms/step - loss: 32.4529 - accuracy: 0.2414 - val_loss: 26.6241 - val_accuracy: 0.0794
Epoch 2/100
390/390 [==============================] - 43s 111ms/step - loss: 16.5834 - accuracy: 0.3436 - val_loss: 15.1204 - val_accuracy: 0.0747
Epoch 3/100
390/390 [==============================] - 43s 110ms/step - loss: 8.8848 - accuracy: 0.3743 - val_loss: 9.1436 - val_accuracy: 0.1341
Epoch 4/100
390/390 [==============================] - 43s 111ms/step - loss: 5.8101 - accuracy: 0.3344 - val_loss: 6.2773 - val_accuracy: 0.2065
Epoch 5/100
390/390 [==============================] - 43s 110ms/step - loss: 3.8329 - accuracy: 0.4061 - val_loss: 4.0463 - val_accuracy: 0.1975
Epoch 6/100
390/390 [==============================] - 43s 111ms/step - loss: 2.5542 - accuracy: 0.4902 - val_loss: 2.8364 - val_accuracy: 0.3431
Epoch 7/100
390/390 [==============================] - 43s 111ms/step - loss: 1.9807 - accuracy: 0.5423 - val_loss: 1.7360 - val_accuracy: 0.5997
Epoch 8/100
390/390 [==============================] - 43s 110ms/step - loss: 1.6318 - accuracy: 0.6030 - val_loss: 1.4858 - val_accuracy: 0.6406
Epoch 9/100
390/390 [==============================] - 43s 110ms/step - loss: 1.4792 - accuracy: 0.6467 - val_loss: 1.3530 - val_accuracy: 0.6992
Epoch 10/100
390/390 [==============================] - 43s 111ms/step - loss: 1.4150 - accuracy: 0.6762 - val_loss: 1.3531 - val_accuracy: 0.7067
Epoch 11/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3802 - accuracy: 0.6937 - val_loss: 1.4302 - val_accuracy: 0.6825
Epoch 12/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3812 - accuracy: 0.7044 - val_loss: 1.4736 - val_accuracy: 0.6738
Epoch 13/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3689 - accuracy: 0.7181 - val_loss: 1.4514 - val_accuracy: 0.7009
Epoch 14/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3655 - accuracy: 0.7253 - val_loss: 1.3662 - val_accuracy: 0.7352
Epoch 15/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3647 - accuracy: 0.7322 - val_loss: 1.4761 - val_accuracy: 0.7165
Epoch 16/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3766 - accuracy: 0.7347 - val_loss: 1.4057 - val_accuracy: 0.7365
Epoch 17/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3753 - accuracy: 0.7415 - val_loss: 1.4914 - val_accuracy: 0.7135
Epoch 18/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3910 - accuracy: 0.7419 - val_loss: 1.3156 - val_accuracy: 0.7672
Epoch 19/100
390/390 [==============================] - 43s 110ms/step - loss: 1.3816 - accuracy: 0.7471 - val_loss: 1.3431 - val_accuracy: 0.7620
Epoch 20/100
390/390 [==============================] - 43s 111ms/step - loss: 1.3789 - accuracy: 0.7518 - val_loss: 1.3912 - val_accuracy: 0.7519
Epoch 21/100
390/390 [==============================] - 43s 111ms/step - loss: 1.2108 - accuracy: 0.7947 - val_loss: 1.1165 - val_accuracy: 0.8103
Epoch 22/100
390/390 [==============================] - 43s 111ms/step - loss: 1.1298 - accuracy: 0.8015 - val_loss: 1.1743 - val_accuracy: 0.7821
Epoch 23/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1014 - accuracy: 0.8036 - val_loss: 1.1973 - val_accuracy: 0.7754
Epoch 24/100
390/390 [==============================] - 43s 111ms/step - loss: 1.0988 - accuracy: 0.8024 - val_loss: 1.0483 - val_accuracy: 0.8239
Epoch 25/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1043 - accuracy: 0.8006 - val_loss: 1.0780 - val_accuracy: 0.8120
Epoch 26/100
390/390 [==============================] - 43s 111ms/step - loss: 1.1017 - accuracy: 0.8043 - val_loss: 1.1248 - val_accuracy: 0.8007
Epoch 27/100
390/390 [==============================] - 43s 111ms/step - loss: 1.1108 - accuracy: 0.8044 - val_loss: 1.1896 - val_accuracy: 0.7886
Epoch 28/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1097 - accuracy: 0.8083 - val_loss: 1.1094 - val_accuracy: 0.8084
Epoch 29/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1199 - accuracy: 0.8077 - val_loss: 1.0931 - val_accuracy: 0.8138
Epoch 30/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1162 - accuracy: 0.8103 - val_loss: 1.0788 - val_accuracy: 0.8243
Epoch 31/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1232 - accuracy: 0.8096 - val_loss: 1.1102 - val_accuracy: 0.8159
Epoch 32/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1274 - accuracy: 0.8102 - val_loss: 1.0281 - val_accuracy: 0.8409
Epoch 33/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1217 - accuracy: 0.8133 - val_loss: 1.0736 - val_accuracy: 0.8330
Epoch 34/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1197 - accuracy: 0.8149 - val_loss: 1.0931 - val_accuracy: 0.8250
Epoch 35/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1271 - accuracy: 0.8158 - val_loss: 1.0571 - val_accuracy: 0.8359
Epoch 36/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1233 - accuracy: 0.8184 - val_loss: 1.0603 - val_accuracy: 0.8357
Epoch 37/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1305 - accuracy: 0.8162 - val_loss: 1.0619 - val_accuracy: 0.8361
Epoch 38/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1219 - accuracy: 0.8208 - val_loss: 1.0899 - val_accuracy: 0.8309
Epoch 39/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1265 - accuracy: 0.8211 - val_loss: 1.0920 - val_accuracy: 0.8290
Epoch 40/100
390/390 [==============================] - 43s 110ms/step - loss: 1.1354 - accuracy: 0.8196 - val_loss: 1.1704 - val_accuracy: 0.8061
Epoch 41/100
390/390 [==============================] - 43s 110ms/step - loss: 1.0093 - accuracy: 0.8526 - val_loss: 1.0161 - val_accuracy: 0.8421
Epoch 42/100
390/390 [==============================] - 43s 110ms/step - loss: 0.9358 - accuracy: 0.8611 - val_loss: 0.9017 - val_accuracy: 0.8652
Epoch 43/100
390/390 [==============================] - 44s 112ms/step - loss: 0.9003 - accuracy: 0.8632 - val_loss: 0.8699 - val_accuracy: 0.8694
Epoch 44/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8908 - accuracy: 0.8629 - val_loss: 0.8867 - val_accuracy: 0.8599
Epoch 45/100
390/390 [==============================] - 43s 112ms/step - loss: 0.8793 - accuracy: 0.8630 - val_loss: 0.8664 - val_accuracy: 0.8692
Epoch 46/100
390/390 [==============================] - 44s 112ms/step - loss: 0.8780 - accuracy: 0.8613 - val_loss: 0.9486 - val_accuracy: 0.8451
Epoch 47/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8788 - accuracy: 0.8609 - val_loss: 0.8404 - val_accuracy: 0.8703
Epoch 48/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8730 - accuracy: 0.8631 - val_loss: 0.8818 - val_accuracy: 0.8624
Epoch 49/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8856 - accuracy: 0.8606 - val_loss: 0.8846 - val_accuracy: 0.8602
Epoch 50/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8759 - accuracy: 0.8631 - val_loss: 0.8386 - val_accuracy: 0.8722
Epoch 51/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8825 - accuracy: 0.8611 - val_loss: 0.8785 - val_accuracy: 0.8624
Epoch 52/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8832 - accuracy: 0.8608 - val_loss: 0.8658 - val_accuracy: 0.8673
Epoch 53/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8764 - accuracy: 0.8662 - val_loss: 0.8661 - val_accuracy: 0.8669
Epoch 54/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8815 - accuracy: 0.8666 - val_loss: 0.8766 - val_accuracy: 0.8641
Epoch 55/100
390/390 [==============================] - 43s 112ms/step - loss: 0.8926 - accuracy: 0.8609 - val_loss: 0.8438 - val_accuracy: 0.8769
Epoch 56/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8738 - accuracy: 0.8675 - val_loss: 0.8833 - val_accuracy: 0.8660
Epoch 57/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8804 - accuracy: 0.8658 - val_loss: 0.9562 - val_accuracy: 0.8444
Epoch 58/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8881 - accuracy: 0.8646 - val_loss: 0.9118 - val_accuracy: 0.8600
Epoch 59/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8849 - accuracy: 0.8670 - val_loss: 0.9061 - val_accuracy: 0.8614
Epoch 60/100
390/390 [==============================] - 43s 111ms/step - loss: 0.8884 - accuracy: 0.8657 - val_loss: 0.9544 - val_accuracy: 0.8461
Epoch 61/100
390/390 [==============================] - 43s 111ms/step - loss: 0.7980 - accuracy: 0.8933 - val_loss: 0.7809 - val_accuracy: 0.8959
Epoch 62/100
390/390 [==============================] - 43s 111ms/step - loss: 0.7493 - accuracy: 0.9025 - val_loss: 0.7918 - val_accuracy: 0.8828
Epoch 63/100
390/390 [==============================] - 43s 110ms/step - loss: 0.7245 - accuracy: 0.9034 - val_loss: 0.7599 - val_accuracy: 0.8918
Epoch 64/100
390/390 [==============================] - 43s 111ms/step - loss: 0.7121 - accuracy: 0.9040 - val_loss: 0.7515 - val_accuracy: 0.8863
Epoch 65/100
390/390 [==============================] - 43s 111ms/step - loss: 0.7030 - accuracy: 0.9029 - val_loss: 0.7403 - val_accuracy: 0.8948
Epoch 66/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6906 - accuracy: 0.9039 - val_loss: 0.7194 - val_accuracy: 0.8937
Epoch 67/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6855 - accuracy: 0.9044 - val_loss: 0.7356 - val_accuracy: 0.8878
Epoch 68/100
390/390 [==============================] - 43s 110ms/step - loss: 0.6756 - accuracy: 0.9045 - val_loss: 0.6830 - val_accuracy: 0.9056
Epoch 69/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6740 - accuracy: 0.9045 - val_loss: 0.7265 - val_accuracy: 0.8886
Epoch 70/100
390/390 [==============================] - 43s 110ms/step - loss: 0.6814 - accuracy: 0.9026 - val_loss: 0.6879 - val_accuracy: 0.9019
Epoch 71/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6755 - accuracy: 0.9039 - val_loss: 0.7177 - val_accuracy: 0.8911
Epoch 72/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6785 - accuracy: 0.9021 - val_loss: 0.7473 - val_accuracy: 0.8863
Epoch 73/100
390/390 [==============================] - 43s 110ms/step - loss: 0.6768 - accuracy: 0.9023 - val_loss: 0.6803 - val_accuracy: 0.9041
Epoch 74/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6738 - accuracy: 0.9047 - val_loss: 0.6993 - val_accuracy: 0.8977
Epoch 75/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6692 - accuracy: 0.9046 - val_loss: 0.7144 - val_accuracy: 0.8889
Epoch 76/100
390/390 [==============================] - 43s 110ms/step - loss: 0.6737 - accuracy: 0.9033 - val_loss: 0.7213 - val_accuracy: 0.8887
Epoch 77/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6708 - accuracy: 0.9040 - val_loss: 0.6898 - val_accuracy: 0.9001
Epoch 78/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6697 - accuracy: 0.9059 - val_loss: 0.7027 - val_accuracy: 0.8958
Epoch 79/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6699 - accuracy: 0.9058 - val_loss: 0.7335 - val_accuracy: 0.8883
Epoch 80/100
390/390 [==============================] - 43s 111ms/step - loss: 0.6732 - accuracy: 0.9036 - val_loss: 0.7308 - val_accuracy: 0.8889
Epoch 81/100
390/390 [==============================] - 43s 110ms/step - loss: 0.6177 - accuracy: 0.9219 - val_loss: 0.6609 - val_accuracy: 0.9096
Epoch 82/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5833 - accuracy: 0.9305 - val_loss: 0.6539 - val_accuracy: 0.9117
Epoch 83/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5712 - accuracy: 0.9306 - val_loss: 0.6307 - val_accuracy: 0.9135
Epoch 84/100
390/390 [==============================] - 43s 111ms/step - loss: 0.5594 - accuracy: 0.9339 - val_loss: 0.6399 - val_accuracy: 0.9093
Epoch 85/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5516 - accuracy: 0.9330 - val_loss: 0.6558 - val_accuracy: 0.9040
Epoch 86/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5413 - accuracy: 0.9355 - val_loss: 0.6353 - val_accuracy: 0.9063
Epoch 87/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5304 - accuracy: 0.9373 - val_loss: 0.6030 - val_accuracy: 0.9161
Epoch 88/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5282 - accuracy: 0.9359 - val_loss: 0.5960 - val_accuracy: 0.9200
Epoch 89/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5223 - accuracy: 0.9352 - val_loss: 0.6296 - val_accuracy: 0.9060
Epoch 90/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5183 - accuracy: 0.9366 - val_loss: 0.6261 - val_accuracy: 0.9055
Epoch 91/100
390/390 [==============================] - 43s 111ms/step - loss: 0.5150 - accuracy: 0.9367 - val_loss: 0.6146 - val_accuracy: 0.9078
Epoch 92/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5156 - accuracy: 0.9348 - val_loss: 0.6255 - val_accuracy: 0.9039
Epoch 93/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5104 - accuracy: 0.9358 - val_loss: 0.5967 - val_accuracy: 0.9139
Epoch 94/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5080 - accuracy: 0.9353 - val_loss: 0.6100 - val_accuracy: 0.9078
Epoch 95/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5020 - accuracy: 0.9373 - val_loss: 0.6247 - val_accuracy: 0.9027
Epoch 96/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5100 - accuracy: 0.9346 - val_loss: 0.6037 - val_accuracy: 0.9106
Epoch 97/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5040 - accuracy: 0.9355 - val_loss: 0.6037 - val_accuracy: 0.9094
Epoch 98/100
390/390 [==============================] - 43s 110ms/step - loss: 0.5032 - accuracy: 0.9354 - val_loss: 0.6025 - val_accuracy: 0.9080
Epoch 99/100
390/390 [==============================] - 43s 110ms/step - loss: 0.4953 - accuracy: 0.9379 - val_loss: 0.5958 - val_accuracy: 0.9122
Epoch 100/100
390/390 [==============================] - 43s 110ms/step - loss: 0.4982 - accuracy: 0.9374 - val_loss: 0.6083 - val_accuracy: 0.9048
313/313 [==============================] - 6s 19ms/step         Accuracy 1:  0.9047999978065491
10000/10000 [==============================] - 5s 542us/step    Accuracy 2:  0.9047999978065491
